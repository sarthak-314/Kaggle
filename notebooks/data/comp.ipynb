{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition Data\r\n",
    "\r\n",
    "Jupyter notebook for the competition data lifecycle\r\n",
    "\r\n",
    "## Sections\r\n",
    "\r\n",
    "### Download the Dataset\r\n",
    "\r\n",
    "### Make Dataframes\r\n",
    "\r\n",
    "### Feature Engineering\r\n",
    "\r\n",
    "### Read Dataset\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Autoreload extensions\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "# Display all \r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell #1: Imports and Constants\r\n",
    "- Import the libs\r\n",
    "- Write some constants for this file like default values for the parametersmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.comp.config import (\r\n",
    "    # Competition specific config\r\n",
    "    DATASET_NAME, LABELS, LABEL_COLS, SPLIT, RENAME_MAP, \r\n",
    "    # Mostly constants\r\n",
    "    HOLDOUT_PERCENTAGE, NUM_FOLDS, RANDOM_STATE, \r\n",
    "    # Paths for the dataset\r\n",
    "    RAW_DATA_PATH, INTERIM_DATA_PATH, PROCESSED_DATA_PATH, \r\n",
    ")\r\n",
    "\r\n",
    "# Default values for the parameters\r\n",
    "INPUT_FOLDER = RAW_DATA_PATH \r\n",
    "OUTPUT_FOLDER = INTERIM_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nCell #2: Read input dataframes from the dataset\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f                                                NaN   \n",
       "2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "\n",
       "                                               label      study_id  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....  5776db0cec75   \n",
       "1                                     none 1 0 0 1 1  ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....  9d514ce429a7   \n",
       "\n",
       "   Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                       0                   1                         0   \n",
       "1                       1                   0                         0   \n",
       "2                       0                   1                         0   \n",
       "\n",
       "   Atypical Appearance  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>img_id</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>435bc0fcb0ab</td>\n",
       "      <td>0d7e69753505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>75b2c9f1f232</td>\n",
       "      <td>149c8d66e874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>5f65421ff6fd</td>\n",
       "      <td>1c716d133c0c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path        img_id  \\\n",
       "0  C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  435bc0fcb0ab   \n",
       "1  C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  75b2c9f1f232   \n",
       "2  C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  5f65421ff6fd   \n",
       "\n",
       "       study_id  \n",
       "0  0d7e69753505  \n",
       "1  149c8d66e874  \n",
       "2  1c716d133c0c  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \r\n",
    "Cell #2: Read input dataframes from the dataset\r\n",
    "\"\"\"\r\n",
    "def merge_input_dataframes(train_img, train_study):\r\n",
    "    image_level_rename_map = { 'StudyInstanceUID': 'study_id', 'id': 'img_id' }\r\n",
    "    train_img.id = train_img.id.str.replace('_image', '')\r\n",
    "    train_img = train_img.rename(columns=image_level_rename_map)\r\n",
    "    study_level_rename_map = {'id':'study_id'}\r\n",
    "    train_study.id = train_study.id.str.replace('_study', '')\r\n",
    "    train_study = train_study.rename(columns=study_level_rename_map)\r\n",
    "    train = train_img.merge(train_study, on='study_id')\r\n",
    "    return train\r\n",
    "\r\n",
    "def read_raw_train(input_folder=INPUT_FOLDER):\r\n",
    "    train_study = pd.read_csv(input_folder / 'train_study_level.csv')\r\n",
    "    train_img = pd.read_csv(input_folder / 'train_image_level.csv')\r\n",
    "    train = merge_input_dataframes(train_img, train_study)\r\n",
    "    return train\r\n",
    "\r\n",
    "def get_path_components(path): \r\n",
    "    normalized_path = os.path.normpath(path)\r\n",
    "    path_components = normalized_path.split(os.sep)\r\n",
    "    return path_components\r\n",
    "\r\n",
    "def read_raw_test(input_folder=INPUT_FOLDER):\r\n",
    "    filepaths = glob.glob(str(input_folder / 'test/**/*dcm'), recursive=True)\r\n",
    "    test = pd.DataFrame({ 'img_path': filepaths })\r\n",
    "    test['img_id'] = test.img_path.map(lambda x: get_path_components(x)[-1].replace('.dcm', ''))\r\n",
    "    test['study_id'] = test.img_path.map(lambda x: get_path_components(x)[-3].replace('.dcm', ''))\r\n",
    "    return test \r\n",
    "\r\n",
    "def read_raw_sample_sub(input_folder=INPUT_FOLDER):\r\n",
    "    sample_sub = pd.read_csv(input_folder / 'sample_submission.csv')\r\n",
    "    return sample_sub\r\n",
    "\r\n",
    "\r\n",
    "#%%\r\n",
    "# Jupyter: Test for the cell \r\n",
    "train = read_raw_train()\r\n",
    "test = read_raw_test()\r\n",
    "sample_sub = read_raw_sample_sub()\r\n",
    "\r\n",
    "train.head(3)\r\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nCell #3: Standardize, Sample and Split\\nStandardize train - add columns like group, stratify, etc\\nSample - sample 1, 5, 20 and 100% of data\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0 1 0 0]    751.75\n",
       "[1 0 0 0]    434.00\n",
       "[0 0 1 0]    277.00\n",
       "[0 0 0 1]    120.75\n",
       "Name: stratify, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FOLD 0 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0 1 0 0]    766\n",
       "[1 0 0 0]    425\n",
       "[0 0 1 0]    275\n",
       "[0 0 0 1]    118\n",
       "Name: stratify, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FOLD 1 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0 1 0 0]    731\n",
       "[1 0 0 0]    447\n",
       "[0 0 1 0]    285\n",
       "[0 0 0 1]    121\n",
       "Name: stratify, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FOLD 2 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0 1 0 0]    758\n",
       "[1 0 0 0]    430\n",
       "[0 0 1 0]    261\n",
       "[0 0 0 1]    134\n",
       "Name: stratify, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FOLD 3 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0 1 0 0]    752\n",
       "[1 0 0 0]    434\n",
       "[0 0 1 0]    287\n",
       "[0 0 0 1]    110\n",
       "Name: stratify, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \r\n",
    "Cell #3: Standardize, Sample and Split\r\n",
    "Standardize train - add columns like group, stratify, etc\r\n",
    "Sample - sample 1, 5, 20 and 100% of data\r\n",
    "\"\"\"\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "def standardize_train(train): \r\n",
    "    # One hot encode and add labels\r\n",
    "    train['one_hot'] = train[LABEL_COLS].apply(lambda row: row.values, axis='columns')\r\n",
    "    train['label'] = train.one_hot.apply(lambda array: np.argmax(array))\r\n",
    "\r\n",
    "    # Add stratify column and group column\r\n",
    "    train['stratify'] = train['one_hot'].apply(str)\r\n",
    "    train['group'] = train['study_id'].apply(str)\r\n",
    "    \r\n",
    "    return train\r\n",
    "\r\n",
    "#%%\r\n",
    "# Jupyter: testing and validation that fold_dfs are similar to each other\r\n",
    "train = standardize_train(train)\r\n",
    "\r\n",
    "print('expected values')\r\n",
    "train.stratify.value_counts() / NUM_FOLDS\r\n",
    "fold_dfs = src.data.utils.get_fold_dfs(train, 'group', NUM_FOLDS)\r\n",
    "for fold_i, fold_df in enumerate(fold_dfs): \r\n",
    "    print(f'--- FOLD {fold_i} ---')\r\n",
    "    fold_df.stratify.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>one_hot</th>\n",
       "      <th>stratify</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>32e5cba874ee</td>\n",
       "      <td>[{'x': 2599.54486, 'y': 329.96207, 'width': 11...</td>\n",
       "      <td>1</td>\n",
       "      <td>18a530e6a802</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>[0 1 0 0]</td>\n",
       "      <td>18a530e6a802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>4f0f03727fad</td>\n",
       "      <td>[{'x': 729.18486, 'y': 696.88445, 'width': 424...</td>\n",
       "      <td>2</td>\n",
       "      <td>09d8a69657ab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0 0 1 0]</td>\n",
       "      <td>09d8a69657ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>6813965b522a</td>\n",
       "      <td>[{'x': 1689.78928, 'y': 536.67926, 'width': 79...</td>\n",
       "      <td>1</td>\n",
       "      <td>cc7cafd867f1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>[0 1 0 0]</td>\n",
       "      <td>cc7cafd867f1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            img_id                                              boxes  label  \\\n",
       "1357  32e5cba874ee  [{'x': 2599.54486, 'y': 329.96207, 'width': 11...      1   \n",
       "2080  4f0f03727fad  [{'x': 729.18486, 'y': 696.88445, 'width': 424...      2   \n",
       "2718  6813965b522a  [{'x': 1689.78928, 'y': 536.67926, 'width': 79...      1   \n",
       "\n",
       "          study_id  Negative for Pneumonia  Typical Appearance  \\\n",
       "1357  18a530e6a802                       0                   1   \n",
       "2080  09d8a69657ab                       0                   0   \n",
       "2718  cc7cafd867f1                       0                   1   \n",
       "\n",
       "      Indeterminate Appearance  Atypical Appearance       one_hot   stratify  \\\n",
       "1357                         0                    0  [0, 1, 0, 0]  [0 1 0 0]   \n",
       "2080                         1                    0  [0, 0, 1, 0]  [0 0 1 0]   \n",
       "2718                         0                    0  [0, 1, 0, 0]  [0 1 0 0]   \n",
       "\n",
       "             group  \n",
       "1357  18a530e6a802  \n",
       "2080  09d8a69657ab  \n",
       "2718  cc7cafd867f1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_train_func(train, num_values_to_sample, random_state=RANDOM_STATE):\r\n",
    "    return train.sample(num_values_to_sample, random_state=random_state)\r\n",
    "\r\n",
    "\r\n",
    "#%%\r\n",
    "# Jupyter: Test sample function\r\n",
    "num_values_to_sample = src.data.utils.get_num_values_to_sample(train, 'twenty') \r\n",
    "sample_train_func(train, num_values_to_sample, RANDOM_STATE).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_0\\one\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_0\\five\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_0\\twenty\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_0\\full\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_1\\one\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_1\\five\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_1\\twenty\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_1\\full\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_2\\one\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_2\\five\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_2\\twenty\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_2\\full\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_3\\one\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_3\\five\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_3\\twenty\n",
      "dataframes created for folder C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\interim\\siim-covid19-detection\\fold_3\\full\n"
     ]
    }
   ],
   "source": [
    "def build_dataframes(input_folder=INPUT_FOLDER, output_folder=OUTPUT_FOLDER): \r\n",
    "    \"\"\"\r\n",
    "    Main function to build the dataframes and the folder\r\n",
    "\r\n",
    "    Args:\r\n",
    "        input_folder (Path): files read from here\r\n",
    "        output_folder (Path): dataframes saved here\r\n",
    "        build_options (OmegaConf): config dict to build the output\r\n",
    "    \"\"\"\r\n",
    "    # Read input dataframes\r\n",
    "    train, test, sample_sub = read_raw_train(input_folder), read_raw_test(input_folder), read_raw_sample_sub(input_folder)\r\n",
    "    \r\n",
    "    # Standardize train\r\n",
    "    train = standardize_train(train)\r\n",
    "    \r\n",
    "    # Split train into holdout    \r\n",
    "    train, holdout = src.data.utils.get_holdout(train, HOLDOUT_PERCENTAGE)\r\n",
    "    pd.to_pickle(train, output_folder/ 'train_full.pkl')\r\n",
    "    for df_name in ['test', 'holdout', 'sample_sub']: \r\n",
    "        df = eval(df_name)\r\n",
    "        pd.to_pickle(df, output_folder / (df_name+'.pkl'))\r\n",
    "    \r\n",
    "    # Save the dataframes\r\n",
    "    build_fold_dfs = lambda df: src.data.utils.get_fold_dfs(df, 'group', NUM_FOLDS)\r\n",
    "    src.data.utils.save_dataframes(train, sample_train_func, build_fold_dfs, NUM_FOLDS, RANDOM_STATE, output_folder)\r\n",
    "    \r\n",
    "    \r\n",
    "if __name__ == '__main__':\r\n",
    "    build_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import glob\r\n",
    "import os \r\n",
    "\r\n",
    "from src.data.utils import feature_col\r\n",
    "from src.data.comp.config import (\r\n",
    "    # Competition specific config\r\n",
    "    DATASET_NAME, LABELS, LABEL_COLS, SPLIT, RENAME_MAP, \r\n",
    "    # Mostly constants\r\n",
    "    HOLDOUT_PERCENTAGE, NUM_FOLDS, RANDOM_STATE, \r\n",
    "    # Paths for the dataset\r\n",
    "    RAW_DATA_PATH, INTERIM_DATA_PATH, PROCESSED_DATA_PATH, \r\n",
    ")\r\n",
    "import src.data.comp.make_dataset\r\n",
    "\r\n",
    "# Default values for the parameters\r\n",
    "INPUT_FOLDER = INTERIM_DATA_PATH\r\n",
    "OUTPUT_FOLDER = PROCESSED_DATA_PATH\r\n",
    "\r\n",
    "# Main functions for feature engineering\r\n",
    "def add_file_path(df, input_folder): \r\n",
    "    @feature_col\r\n",
    "    def file_path(filepaths, img_id, study_id): \r\n",
    "        for filepath in filepaths: \r\n",
    "            if img_id in filepath and study_id in filepath: \r\n",
    "                return filepath\r\n",
    "        return None\r\n",
    "    glob_re = str(input_folder/ '**/*dcm')\r\n",
    "    filepaths = glob.glob(glob_re, recursive=True)\r\n",
    "    df = file_path(df, filepaths=filepaths)\r\n",
    "    return df    \r\n",
    "\r\n",
    "# Feature Engineering Pipeline\r\n",
    "def common_feature_engineering_pipeline(df): \r\n",
    "    return df\r\n",
    "\r\n",
    "def train_pipeline(train, **kwargs): \r\n",
    "    train = common_feature_engineering_pipeline(train)\r\n",
    "    train = add_file_path(train, input_folder=RAW_DATA_PATH / 'train')\r\n",
    "    train = train.reset_index(drop=True)\r\n",
    "    return train \r\n",
    "\r\n",
    "def test_pipeline(test, **kwargs): \r\n",
    "    test = common_feature_engineering_pipeline(test)\r\n",
    "    return test\r\n",
    "\r\n",
    "def read_all_pkl_files(input_folder): \r\n",
    "    all_pkl_files_in_input_folder = glob.glob(str(input_folder / '**/*.pkl'), recursive=True)\r\n",
    "    return all_pkl_files_in_input_folder\r\n",
    "\r\n",
    "def get_output_path(input_path, input_folder, output_folder): \r\n",
    "    \"\"\"\r\n",
    "    Get output path for the dataframe by replacing input folder in the input path by output path\r\n",
    "    \"\"\"\r\n",
    "    output_path = str(input_path).replace(str(input_folder), str(output_folder))\r\n",
    "    return output_path\r\n",
    "\r\n",
    "def apply_train_feature_engineering_pipeline(input_folder=INPUT_FOLDER, output_folder=OUTPUT_FOLDER, train_pipeline=train_pipeline): \r\n",
    "    all_pkl_files = read_all_pkl_files(input_folder)\r\n",
    "    for pkl_path in all_pkl_files: \r\n",
    "        output_path = get_output_path(pkl_path, input_folder, output_folder)\r\n",
    "        is_train = 'train' in pkl_path or 'valid' in pkl_path\r\n",
    "        if not is_train: continue\r\n",
    "        df = pd.read_pickle(pkl_path)\r\n",
    "        df = train_pipeline(df)\r\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\r\n",
    "        df.to_pickle(output_path)\r\n",
    "\r\n",
    "\r\n",
    "def apply_test_feature_engineering_pipeline(raw_input_folder=RAW_DATA_PATH, test_pipeline=test_pipeline):\r\n",
    "    test = src.data.comp.make_dataset.read_raw_test(raw_input_folder)\r\n",
    "    test = test_pipeline(test)\r\n",
    "    return test\r\n",
    "\r\n",
    "def save_test(output_folder=OUTPUT_FOLDER):\r\n",
    "    test = apply_test_feature_engineering_pipeline()\r\n",
    "    save_path = output_folder / 'test.pkl'\r\n",
    "    test.to_pickle(save_path)\r\n",
    "    print(f'test saved at {save_path}')\r\n",
    "    \r\n",
    "\r\n",
    "if __name__ == '__main__': \r\n",
    "    apply_train_feature_engineering_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path took 0.1046602725982666 seconds to execute for df of length 6270\n",
      "file_path took 0.09667801856994629 seconds to execute for df of length 6270\n",
      "file_path took 0.003986358642578125 seconds to execute for df of length 235\n",
      "file_path took 0.002990245819091797 seconds to execute for df of length 79\n",
      "file_path took 0.029905319213867188 seconds to execute for df of length 1584\n",
      "file_path took 0.07574462890625 seconds to execute for df of length 4750\n",
      "file_path took 0.07674312591552734 seconds to execute for df of length 4702\n",
      "file_path took 0.023920774459838867 seconds to execute for df of length 1568\n",
      "file_path took 0.0259096622467041 seconds to execute for df of length 1584\n",
      "file_path took 0.09170150756835938 seconds to execute for df of length 4750\n",
      "file_path took 0.001995086669921875 seconds to execute for df of length 47\n",
      "file_path took 0.0009970664978027344 seconds to execute for df of length 16\n",
      "file_path took 0.02691030502319336 seconds to execute for df of length 1584\n",
      "file_path took 0.11361098289489746 seconds to execute for df of length 4750\n",
      "file_path took 0.017937898635864258 seconds to execute for df of length 940\n",
      "file_path took 0.007973909378051758 seconds to execute for df of length 314\n",
      "file_path took 0.03288722038269043 seconds to execute for df of length 1584\n",
      "file_path took 0.09768104553222656 seconds to execute for df of length 4750\n",
      "file_path took 0.0070209503173828125 seconds to execute for df of length 235\n",
      "file_path took 0.002989053726196289 seconds to execute for df of length 79\n",
      "file_path took 0.028902292251586914 seconds to execute for df of length 1584\n",
      "file_path took 0.0758519172668457 seconds to execute for df of length 4750\n",
      "file_path took 0.07781076431274414 seconds to execute for df of length 4702\n",
      "file_path took 0.022923707962036133 seconds to execute for df of length 1568\n",
      "file_path took 0.02890491485595703 seconds to execute for df of length 1584\n",
      "file_path took 0.0756998062133789 seconds to execute for df of length 4750\n",
      "file_path took 0.0019969940185546875 seconds to execute for df of length 47\n",
      "file_path took 0.0009987354278564453 seconds to execute for df of length 16\n",
      "file_path took 0.03189659118652344 seconds to execute for df of length 1584\n",
      "file_path took 0.08969473838806152 seconds to execute for df of length 4750\n",
      "file_path took 0.01694464683532715 seconds to execute for df of length 940\n",
      "file_path took 0.005978107452392578 seconds to execute for df of length 314\n",
      "file_path took 0.028903722763061523 seconds to execute for df of length 1584\n",
      "file_path took 0.07076835632324219 seconds to execute for df of length 4750\n",
      "file_path took 0.005981922149658203 seconds to execute for df of length 236\n",
      "file_path took 0.002008199691772461 seconds to execute for df of length 78\n",
      "file_path took 0.03388071060180664 seconds to execute for df of length 1583\n",
      "file_path took 0.08963584899902344 seconds to execute for df of length 4751\n",
      "file_path took 0.07975172996520996 seconds to execute for df of length 4703\n",
      "file_path took 0.02690410614013672 seconds to execute for df of length 1567\n",
      "file_path took 0.0299527645111084 seconds to execute for df of length 1583\n",
      "file_path took 0.07974100112915039 seconds to execute for df of length 4751\n",
      "file_path took 0.0010035037994384766 seconds to execute for df of length 47\n",
      "file_path took 0.0010058879852294922 seconds to execute for df of length 16\n",
      "file_path took 0.0318446159362793 seconds to execute for df of length 1583\n",
      "file_path took 0.0907590389251709 seconds to execute for df of length 4751\n",
      "file_path took 0.01798081398010254 seconds to execute for df of length 941\n",
      "file_path took 0.008970260620117188 seconds to execute for df of length 313\n",
      "file_path took 0.030942678451538086 seconds to execute for df of length 1583\n",
      "file_path took 0.08173060417175293 seconds to execute for df of length 4751\n",
      "file_path took 0.004920005798339844 seconds to execute for df of length 236\n",
      "file_path took 0.0029904842376708984 seconds to execute for df of length 78\n",
      "file_path took 0.028902292251586914 seconds to execute for df of length 1583\n",
      "file_path took 0.07773590087890625 seconds to execute for df of length 4751\n",
      "file_path took 0.08368659019470215 seconds to execute for df of length 4703\n",
      "file_path took 0.025921344757080078 seconds to execute for df of length 1567\n",
      "file_path took 0.032881975173950195 seconds to execute for df of length 1583\n",
      "file_path took 0.08965420722961426 seconds to execute for df of length 4751\n",
      "file_path took 0.002974271774291992 seconds to execute for df of length 48\n",
      "file_path took 0.0020034313201904297 seconds to execute for df of length 15\n",
      "file_path took 0.035881996154785156 seconds to execute for df of length 1583\n",
      "file_path took 0.07874083518981934 seconds to execute for df of length 4751\n",
      "file_path took 0.01687788963317871 seconds to execute for df of length 941\n",
      "file_path took 0.005966663360595703 seconds to execute for df of length 313\n",
      "file_path took 0.029896974563598633 seconds to execute for df of length 1583\n",
      "file_path took 0.07675647735595703 seconds to execute for df of length 4751\n"
     ]
    }
   ],
   "source": [
    "# Main functions for feature engineering\r\n",
    "def add_file_path(df, input_folder): \r\n",
    "    @feature_col\r\n",
    "    def file_path(filepaths, img_id, study_id): \r\n",
    "        for filepath in filepaths: \r\n",
    "            if img_id in filepath and study_id in filepath: \r\n",
    "                return filepath\r\n",
    "        return None\r\n",
    "    glob_re = str(input_folder/ '**/*dcm')\r\n",
    "    filepaths = glob.glob(glob_re, recursive=True)\r\n",
    "    df = file_path(df, filepaths=filepaths)\r\n",
    "    return df    \r\n",
    "\r\n",
    "# Feature Engineering Pipeline\r\n",
    "def common_feature_engineering_pipeline(df): \r\n",
    "    return df\r\n",
    "\r\n",
    "def train_pipeline(train, **kwargs): \r\n",
    "    train = common_feature_engineering_pipeline(train)\r\n",
    "    train = add_file_path(train, input_folder=RAW_DATA_PATH / 'train')\r\n",
    "    train = train.reset_index(drop=True)\r\n",
    "    return train \r\n",
    "\r\n",
    "def test_pipeline(test, **kwargs): \r\n",
    "    test = common_feature_engineering_pipeline(test)\r\n",
    "    return test\r\n",
    " \r\n",
    "\r\n",
    "def read_all_pkl_files(input_folder): \r\n",
    "    all_pkl_files_in_input_folder = glob.glob(str(input_folder / '**/*.pkl'), recursive=True)\r\n",
    "    return all_pkl_files_in_input_folder\r\n",
    "\r\n",
    "def get_output_path(input_path, input_folder, output_folder): \r\n",
    "    \"\"\"\r\n",
    "    Get output path for the dataframe by replacing input folder in the input path by output path\r\n",
    "    \"\"\"\r\n",
    "    output_path = str(input_path).replace(str(input_folder), str(output_folder))\r\n",
    "    return output_path\r\n",
    "\r\n",
    "def apply_train_feature_engineering_pipeline(input_folder=INPUT_FOLDER, output_folder=OUTPUT_FOLDER, train_pipeline=train_pipeline): \r\n",
    "    all_pkl_files = read_all_pkl_files(input_folder)\r\n",
    "    for pkl_path in all_pkl_files: \r\n",
    "        output_path = get_output_path(pkl_path, input_folder, output_folder)\r\n",
    "        is_train = 'train' in pkl_path or 'valid' in pkl_path\r\n",
    "        if not is_train: continue\r\n",
    "        df = pd.read_pickle(pkl_path)\r\n",
    "        df = train_pipeline(df)\r\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\r\n",
    "        df.to_pickle(output_path)\r\n",
    "\r\n",
    "\r\n",
    "def apply_test_feature_engineering_pipeline(raw_input_folder=RAW_DATA_PATH, test_pipeline=test_pipeline):\r\n",
    "    test = src.data.comp.make_dataset.read_raw_test(raw_input_folder)\r\n",
    "    test = test_pipeline(test)\r\n",
    "    return test\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__': \r\n",
    "    apply_train_feature_engineering_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>one_hot</th>\n",
       "      <th>stratify</th>\n",
       "      <th>group</th>\n",
       "      <th>img_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a344911414ce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>07c985cdc2e3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>07c985cdc2e3</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcb1d52e4eab</td>\n",
       "      <td>[{'x': 1558.82736, 'y': 938.61835, 'width': 63...</td>\n",
       "      <td>1</td>\n",
       "      <td>76122cbd97f4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>76122cbd97f4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5af8dfe95d88</td>\n",
       "      <td>[{'x': 2944.08004, 'y': 556.8, 'width': 1061.4...</td>\n",
       "      <td>1</td>\n",
       "      <td>022f9b3cfd91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>022f9b3cfd91</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_id                                              boxes  label  \\\n",
       "0  a344911414ce                                                NaN      0   \n",
       "1  bcb1d52e4eab  [{'x': 1558.82736, 'y': 938.61835, 'width': 63...      1   \n",
       "2  5af8dfe95d88  [{'x': 2944.08004, 'y': 556.8, 'width': 1061.4...      1   \n",
       "\n",
       "       study_id  Negative for Pneumonia  Typical Appearance  \\\n",
       "0  07c985cdc2e3                       1                   0   \n",
       "1  76122cbd97f4                       0                   1   \n",
       "2  022f9b3cfd91                       0                   1   \n",
       "\n",
       "   Indeterminate Appearance  Atypical Appearance       one_hot      stratify  \\\n",
       "0                         0                    0  [1, 0, 0, 0]  [1, 0, 0, 0]   \n",
       "1                         0                    0  [0, 1, 0, 0]  [0, 1, 0, 0]   \n",
       "2                         0                    0  [0, 1, 0, 0]  [0, 1, 0, 0]   \n",
       "\n",
       "          group img_path  fold file_path  \n",
       "0  07c985cdc2e3     None     1      None  \n",
       "1  76122cbd97f4     None     0      None  \n",
       "2  022f9b3cfd91     None     2      None  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = OUTPUT_FOLDER / 'fold_3' / 'full' / 'train.pkl'\r\n",
    "train = pd.read_pickle(train_path)\r\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>img_id</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>435bc0fcb0ab</td>\n",
       "      <td>0d7e69753505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>75b2c9f1f232</td>\n",
       "      <td>149c8d66e874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>5f65421ff6fd</td>\n",
       "      <td>1c716d133c0c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>84dd9eff2ecf</td>\n",
       "      <td>2ebd6459c760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>6fd7971538df</td>\n",
       "      <td>39a02fb99c60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>31c07523a69a</td>\n",
       "      <td>81c860c6efe8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>aba653aebd55</td>\n",
       "      <td>a134c7f3e533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>09443dcb865f</td>\n",
       "      <td>a134c7f3e533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>89426c0c18a8</td>\n",
       "      <td>a150ce575fd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>1c1c48cb66e4</td>\n",
       "      <td>b647d5c8422e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>639f6bf3c727</td>\n",
       "      <td>b64b5a8cec28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>440de3bfe05a</td>\n",
       "      <td>b66d6c34498e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>e5c56ef2d194</td>\n",
       "      <td>f76a41789560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...</td>\n",
       "      <td>a67ef603134f</td>\n",
       "      <td>fd193f9220cb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_path        img_id  \\\n",
       "0   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  435bc0fcb0ab   \n",
       "1   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  75b2c9f1f232   \n",
       "2   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  5f65421ff6fd   \n",
       "3   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  84dd9eff2ecf   \n",
       "4   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  6fd7971538df   \n",
       "5   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  31c07523a69a   \n",
       "6   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  aba653aebd55   \n",
       "7   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  09443dcb865f   \n",
       "8   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  89426c0c18a8   \n",
       "9   C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  1c1c48cb66e4   \n",
       "10  C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  639f6bf3c727   \n",
       "11  C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  440de3bfe05a   \n",
       "12  C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  e5c56ef2d194   \n",
       "13  C:\\Users\\sarth\\Desktop\\kaggle-v2\\data\\raw\\siim...  a67ef603134f   \n",
       "\n",
       "        study_id  \n",
       "0   0d7e69753505  \n",
       "1   149c8d66e874  \n",
       "2   1c716d133c0c  \n",
       "3   2ebd6459c760  \n",
       "4   39a02fb99c60  \n",
       "5   81c860c6efe8  \n",
       "6   a134c7f3e533  \n",
       "7   a134c7f3e533  \n",
       "8   a150ce575fd8  \n",
       "9   b647d5c8422e  \n",
       "10  b64b5a8cec28  \n",
       "11  b66d6c34498e  \n",
       "12  f76a41789560  \n",
       "13  fd193f9220cb  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_full', 'test', 'holdout', 'train', 'valid', 'valid_75', 'valid_25', 'tr', 'te', 'val'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working!\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "import pandas as pd\r\n",
    "import glob\r\n",
    "import os \r\n",
    "\r\n",
    "from src.data.utils import feature_col\r\n",
    "from src.data.comp.config import (\r\n",
    "    # Competition specific config\r\n",
    "    DATASET_NAME, LABELS, LABEL_COLS, SPLIT, RENAME_MAP, \r\n",
    "    # Mostly constants\r\n",
    "    HOLDOUT_PERCENTAGE, NUM_FOLDS, RANDOM_STATE, \r\n",
    "    # Paths for the dataset\r\n",
    "    RAW_DATA_PATH, INTERIM_DATA_PATH, PROCESSED_DATA_PATH, \r\n",
    ")\r\n",
    "import src.data.comp.build_features\r\n",
    "import src.data.comp.make_dataset\r\n",
    "\r\n",
    "# Constants to be imported \r\n",
    "FEATURE_COLS = ['file_path'] # X for the model\r\n",
    "TARGET_COL = 'label' # y for the model\r\n",
    "\r\n",
    "def read_dataframe(df_name, fold=0, debug_percentage='full', input_folder=PROCESSED_DATA_PATH): \r\n",
    "    df_path = input_folder / f'fold_{fold}' / debug_percentage / f'{df_name}.pkl'\r\n",
    "    df = pd.read_pickle(df_path)\r\n",
    "    return df\r\n",
    "\r\n",
    "def read_dataframes(fold=0, debug_percentage='full', input_folder=PROCESSED_DATA_PATH):\r\n",
    "    res = {}\r\n",
    "    # read the files from the outer folder\r\n",
    "    res['train_full'] = pd.read_pickle(input_folder / 'train_full.pkl')\r\n",
    "    res['test'] = pd.read_pickle(input_folder / 'test.pkl')\r\n",
    "    res['holdout'] = pd.read_pickle(input_folder / 'holdout.pkl')\r\n",
    "    \r\n",
    "    # read the files from the inner folder \r\n",
    "    inner_folder = input_folder / f'fold_{fold}' / debug_percentage\r\n",
    "    res['train'] = pd.read_pickle(inner_folder / 'train.pkl')\r\n",
    "    res['valid'] = pd.read_pickle(inner_folder / 'valid.pkl')\r\n",
    "    res['valid_75'] = pd.read_pickle(inner_folder / 'valid_75.pkl')\r\n",
    "    res['valid_25'] = pd.read_pickle(inner_folder / 'valid_25.pkl')\r\n",
    "    \r\n",
    "    # make some testing files\r\n",
    "    res['tr'] = res['train'].head(10)\r\n",
    "    res['te'] = res['test'].head(5)\r\n",
    "    res['val'] = res['valid'].head(5)\r\n",
    "    \r\n",
    "    return res\r\n",
    "    \r\n",
    "\r\n",
    "def read_test(input_folder=RAW_DATA_PATH): \r\n",
    "    test = src.data.comp.make_dataset.read_raw_test(input_folder)\r\n",
    "    test = src.data.comp.build_features.apply_test_feature_engineering_pipeline(input_folder)\r\n",
    "    return test\r\n",
    "\r\n",
    "\r\n",
    "def read_file(file_path):\r\n",
    "    return read_x \r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    read_test()\r\n",
    "    read_dataframes().keys()\r\n",
    "    print('working!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\train_full.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\five\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\five\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\five\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\five\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\full\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\full\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\full\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\full\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\one\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\one\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\one\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\one\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\twenty\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\twenty\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\twenty\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_0\\\\twenty\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\five\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\five\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\five\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\five\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\full\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\full\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\full\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\full\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\one\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\one\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\one\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\one\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\twenty\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\twenty\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\twenty\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_1\\\\twenty\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\five\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\five\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\five\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\five\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\full\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\full\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\full\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\full\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\one\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\one\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\one\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\one\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\twenty\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\twenty\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\twenty\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_2\\\\twenty\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\five\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\five\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\five\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\five\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\full\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\full\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\full\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\full\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\one\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\one\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\one\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\one\\\\valid_75.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\twenty\\\\train.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\twenty\\\\valid.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\twenty\\\\valid_25.pkl',\n",
       " 'C:\\\\Users\\\\sarth\\\\Desktop\\\\kaggle-v2\\\\data\\\\processed\\\\siim-covid19-detection\\\\fold_3\\\\twenty\\\\valid_75.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[file for file in glob.glob(str(PROCESSED_DATA_PATH / '**/*pkl'), recursive=True) ]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d80601e53b25ae79ea193be14c277f9b183edcb9bd2d70481fc2c807579e89"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}