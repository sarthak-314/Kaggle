{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\r\n",
    "\r\n",
    "## CompDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \r\n",
    "\r\n",
    "from src.data.comp.read_dataset import (\r\n",
    "    FEATURE_COLS, TARGET_COL, \r\n",
    "    read_dataframes, read_input_file\r\n",
    ")\r\n",
    "\r\n",
    "from src.aug.apply_transform import train_transform_comp\r\n",
    "\r\n",
    "class CompDatasetTrain(torch.utils.data.Dataset): \r\n",
    "    def __init__(self, df, transform):\r\n",
    "        \"\"\"\r\n",
    "        Build torch Dataset for the train/valid dataframe \r\n",
    "        \r\n",
    "        Args:\r\n",
    "            df (DataFrame): train or valid dataframe\r\n",
    "            transform (function): function to apply to input file to augment it\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            output_dict (dict): output dictionary for each input containing features and target\r\n",
    "        \"\"\" \r\n",
    "        self.df = df\r\n",
    "        self.transform = transform\r\n",
    "    \r\n",
    "    def __getitem__(self, idx): \r\n",
    "        row = self.df.iloc[idx]\r\n",
    "        \r\n",
    "        # read the main input \r\n",
    "        img = read_input_file(row.file_path)\r\n",
    "        img = self.transform(img)\r\n",
    "        \r\n",
    "        # build all the features for the input\r\n",
    "        feature_dict = {\r\n",
    "            'img': torch.tensor(img, dtype=torch.float)\r\n",
    "        }\r\n",
    "        \r\n",
    "        # add the target to the feature dict to make output dict\r\n",
    "        output_dict = feature_dict\r\n",
    "        target = row.label \r\n",
    "        output_dict['target'] = torch.tensor(target, dtype=torch.long)\r\n",
    "        return output_dict\r\n",
    "    \r\n",
    "    def __len__(self): \r\n",
    "        return len(self.df)\r\n",
    "\r\n",
    "\r\n",
    "class CompDatasetTest(torch.utils.data.Dataset): \r\n",
    "    def __init__(self, df):\r\n",
    "        self.df = df\r\n",
    "    \r\n",
    "    def __getitem__(self, idx): \r\n",
    "        row = self.df.iloc[idx]\r\n",
    "        \r\n",
    "        # read the main input \r\n",
    "        img = read_input_file(row.file_path)\r\n",
    "        img = self.transform(img)\r\n",
    "        \r\n",
    "        # build all the features for the input\r\n",
    "        feature_dict = {\r\n",
    "            'img': torch.tensor(img, dtype=torch.float)\r\n",
    "        }\r\n",
    "        # no labels for test\r\n",
    "        output_dict = feature_dict\r\n",
    "        return output_dict\r\n",
    "    \r\n",
    "    def __len__(self): \r\n",
    "        return len(self.df)    \r\n",
    "\r\n",
    "# Jupyter Testing\r\n",
    "train, test = read_dataframes()['train'], read_dataframes()['test']\r\n",
    "train_ds = CompDatasetTrain(train, train_transform_comp)\r\n",
    "test_ds = CompDatasetTest(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_full', 'test', 'holdout', 'train', 'valid', 'valid_75', 'valid_25', 'tr', 'te', 'val'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataframes().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CompDatasetTrain at 0x2cc7f1d9700>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CompDataModule(pl.LightningDataModule):\r\n",
    "    def __init__(self, dataframes, transforms, batch_size=32, num_workers=8):\r\n",
    "        \"\"\"\r\n",
    "        :param dataframes (dict): processed train, valid and test dataframes\r\n",
    "        :param transforms (dict): dict with transform function for train, valid, test\r\n",
    "        \"\"\"\r\n",
    "        super().__init__()\r\n",
    "        self.dataframes = dataframes\r\n",
    "        self.transforms = transforms \r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.num_workers = num_workers\r\n",
    "\r\n",
    "    def train_dataloader(self):\r\n",
    "        train_df = self.dataframes['train']\r\n",
    "        train_transform = self.transforms['train']\r\n",
    "        train_ds = CompDatasetTrain(train_df, train_transform)\r\n",
    "        train_loader = torch.utils.data.DataLoader(\r\n",
    "            train_ds, batch_size=self.batch_size, \r\n",
    "            num_workers = self.num_workers, # you should optimize this \r\n",
    "            pin_memory = torch.cuda.is_available(), \r\n",
    "            shuffle = True, drop_last = True, \r\n",
    "        )\r\n",
    "        return train_loader\r\n",
    "\r\n",
    "    def val_dataloader(self):\r\n",
    "        valid_df = self.dataframes['valid']\r\n",
    "        valid_transform = self.transforms['valid']\r\n",
    "        valid_ds = CompDatasetTrain(valid_df, valid_transform)\r\n",
    "        val_loader = torch.utils.data.DataLoader(\r\n",
    "            valid_ds, batch_size=self.batch_size, \r\n",
    "            num_workers = self.num_workers, \r\n",
    "            pin_memory = torch.cuda.is_available(), \r\n",
    "            shuffle = True, drop_last = False, \r\n",
    "        )\r\n",
    "        return val_loader\r\n",
    "\r\n",
    "    def test_dataloader(self): \r\n",
    "        test_df = self.dataframes['test']\r\n",
    "        test_ds = CompDatasetTest(test_df)\r\n",
    "        test_loader = torch.utils.data.DataLoader(\r\n",
    "            test_ds, batch_size=self.batch_size, \r\n",
    "            num_workers=self.num_workers, \r\n",
    "            pin_memory=torch.cuda.is_available(), \r\n",
    "            shuffle=False, drop_last=False,\r\n",
    "        )\r\n",
    "        return test_loader\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "⚒ Ideas & Improvements ⚒\r\n",
    "-------------------------\r\n",
    "- add dataframes metadata like num_classes as @property \r\n",
    "- \r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d80601e53b25ae79ea193be14c277f9b183edcb9bd2d70481fc2c807579e89"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}