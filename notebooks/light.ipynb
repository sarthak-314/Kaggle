{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ PyTorch Lightning \r\n",
    "\r\n",
    "Main notebook for running torch experiments and training torch models\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload extensions\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "# Import the package \r\n",
    "import src \r\n",
    "\r\n",
    "# Display all \r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.light.data.comp.datamodule import CompDataModule\r\n",
    "from src.data.comp.read_dataset import read_dataframes\r\n",
    "from src.aug.apply_transform import comp_transforms\r\n",
    "\r\n",
    "dataframes = read_dataframes()\r\n",
    "data_module = CompDataModule(dataframes, comp_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config for callbacks, trainer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating callback <pytorch_lightning.callbacks.BackboneFinetuning>\n",
      "Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>\n",
      "Instantiating callback <pytorch_lightning.callbacks.LearningRateMonitor>\n",
      "Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>\n",
      "Instantiating callback <pl_bolts.callbacks.printing.PrintTableMetricsCallback>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating callback <pl_bolts.callbacks.TrainingDataMonitor>\n",
      "Instantiating callback <pl_bolts.callbacks.ModuleDataMonitor>\n",
      "Instantiating callback <pl_bolts.callbacks.BatchGradientVerificationCallback>\n",
      "Initializing logger <pytorch_lightning.loggers.TensorBoardLogger>\n",
      "Initializing logger <pytorch_lightning.loggers.WandbLogger>\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\r\n",
    "from termcolor import colored\r\n",
    "\r\n",
    "from src.light.config import (\r\n",
    "    CALLBACKS_CONFIG, LOGGERS_CONFIG, TRAINER_CONFIG, \r\n",
    ")\r\n",
    "import src.light.trainer\r\n",
    "\r\n",
    "PRINT_ALL = False\r\n",
    "if PRINT_ALL: \r\n",
    "    print(colored('------ TRAINER CONFIG ------', 'green'))\r\n",
    "    print(colored(f'TRAINER keys: {list(TRAINER_CONFIG.keys())}', 'magenta'))\r\n",
    "    print(OmegaConf.to_yaml(TRAINER_CONFIG))\r\n",
    "\r\n",
    "    print(colored('------ CALLBACKS CONFIG ------', 'green'))\r\n",
    "    print(colored(f'CALLBACKS keys: {list(CALLBACKS_CONFIG.keys())}', 'magenta'))\r\n",
    "    print(OmegaConf.to_yaml(CALLBACKS_CONFIG))\r\n",
    "\r\n",
    "    print(colored('------ LOGGERS CONFIG ------', 'green'))\r\n",
    "    print(colored(f'LOGGERS keys: {list(LOGGERS_CONFIG.keys())}', 'magenta'))\r\n",
    "    print(OmegaConf.to_yaml(LOGGERS_CONFIG))\r\n",
    "    \r\n",
    "    \r\n",
    "callbacks = src.light.trainer.get_callbacks(CALLBACKS_CONFIG)\r\n",
    "loggers = src.light.trainer.get_loggers(LOGGERS_CONFIG)\r\n",
    "\r\n",
    "trainer = src.light.trainer.build_trainer(TRAINER_CONFIG, callbacks, loggers, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'latent_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c4672065d15e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClassificationTask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sarth\\desktop\\kaggle-v2\\src\\light\\models\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, backbone, num_classes)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         self.linear = nn.Sequential(\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'latent_dim'"
     ]
    }
   ],
   "source": [
    "import src.light.models.model\r\n",
    "from torch import nn\r\n",
    "backbone = lambda _: 2\r\n",
    "\r\n",
    "FINAL_LAYER = nn.Sequential(\r\n",
    "    nn.Linear(backbone.latent_dim, 64), \r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Linear(64, data_module.num_classes), \r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "task = src.light.models.model.ClassificationTask(backbone)\r\n",
    "trainer.fit(task, data_module)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d80601e53b25ae79ea193be14c277f9b183edcb9bd2d70481fc2c807579e89"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}