# KERAS CALLBACKS

# Save the keras model at {filepath} every {epoch}
model_checkpoint:
  _target_: keras.callbacks.ModelCheckpoint
  filepath: tensorflow_models/epoch_{epoch:02d}-loss_{val/loss:.4f}-acc_{val/acc:.4f}
  verbose: 1
  save_best_only: true
  monitor: 'val_loss' 
  mode: 'min'
  save_weights_only: false
  save_freq: 'epoch' 
  options: null


tensorboard:
  _target_: keras.callbacks.TensorBoard
  log_dir: tf-logs
  write_images: true # write model weights as images to visualize
  profile_batch: 2 # ???


early_stopping: 
  _target_: keras.callbacks.EarlyStopping
  monitor: 'val_loss'
  mode: 'min'
  patience: 5
  restore_best_weights: true # use last step model vs best model

# stop the training on an NaN loss
terminate_on_nan: 
  _target_: keras.callbacks.TerminateOnNaN

# reduce learning 
reduce_lr_on_plateau: 
  _target_: keras.callbacks.ReduceLROnPlateau
  monitor: 'val_loss'
  factor: 0.25
  mode: 'min'
  patience: 5
  verbose: 1
  cooldown: 1

# stop training after some time
time_stopping:
  _target_: tfa.callbacks.TimeStopping
  seconds: 28800

# callback that prints metrics 
prog_bar: 
  _target_: keras.callbacks.ProgbarLogger
  count_mode: 'samples' # count steps or samples

# TODO: Check out model averaging, moving average optimizers n shit



